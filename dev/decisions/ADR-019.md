# ADR-019: RAG corpus construction, coverage reporting, and scaling plan

## Date
2025-12-15

## Status
Accepted

## Context

MolSys-AI serves as a specialist assistant for the UIBCDF MolSysSuite ecosystem (MolSysMT,
MolSysViewer, TopoMT, PyUnitWizard, and related tools).

To answer accurately and reduce API hallucinations, the chat backend uses RAG over a
local, reproducible corpus snapshot built from the upstream tool repositories.

Constraints and observations:

- Upstream documentation is mostly `*.md` and `*.ipynb` (with some `*.rst`), and is served
  via Sphinx on `https://www.uibcdf.org/<tool>/...`.
- Running upstream Sphinx builds (`conf.py`) is not a reliable requirement for the server
  environment (it may require importing/installing toolchains we explicitly keep separate
  from the vLLM environment).
- We need stable deep links for citations without compiling HTML.
- We want the model to have access to API details (docstrings and examples) without
  importing upstream packages (to avoid dependency conflicts).
- The RAG corpus will be refreshed regularly because upstream tool docs evolve.
- The system runs on GPU hosts (3× RTX 2080 Ti) and a separate offline node is available
  for heavier batch jobs (corpus refreshes, derived corpus generation, training).

## Decision

### 1) Corpus sources (literal snapshot)

We build a **literal** corpus snapshot from sibling repositories by copying text sources:

- include directories: `docs/`, `doc/`, `examples/`, `devguide/`,
- include root files: `README*.md`, `README*.rst`, `dev_guide.md`, `CHANGELOG*.md`, etc.,
- include extensions: `.md`, `.rst`, `.txt`, `.ipynb`.

This is implemented in `dev/sync_rag_corpus.py` and writes to:

- `server/chat_api/data/docs/` (default)
- plus `_manifest.json` for provenance (repo paths, git SHAs, checksums).

### 2) Large-file policy (include by default)

To avoid silently losing important tutorials:

- Text files larger than `--max-bytes` are **included by truncation** (default behavior).
- Notebooks are **compacted** (outputs/metadata stripped) and bounded by `--max-bytes-ipynb`.

This keeps the snapshot indexable while preventing size blow-ups from notebook outputs.

### 3) Stable deep links for citations (anchors)

We extract explicit MyST labels `(Label)=` from `docs/` sources and generate:

- `server/chat_api/data/anchors.json`

This enables deep links like:

- `https://www.uibcdf.org/<tool>/<page>.html#<Label>`

without compiling Sphinx HTML.

### 4) API surface from docstrings without imports (derived snapshot)

To expose API details (signatures + docstrings) without importing upstream packages, we
generate a derived corpus layer:

- `server/chat_api/data/docs/<project>/api_surface/...`
- `server/chat_api/data/docs/_api_surface.json`

Extraction uses `ast` parsing only (no imports). Defaults are **no artificial caps**:

- `--api-surface-max-modules 0` (no limit)
- `--api-surface-max-symbols 0` (no limit)
- docstring excerpts default to unlimited chars

### 4b) Additional code-aware derived layers (symbol cards + recipes)

For API-heavy questions, “document-page chunks” are often less useful than symbol-first retrieval.
We therefore support additional derived layers (no imports):

- **Symbol cards** (`docs/<project>/symbol_cards/`): one document per function/class/method (signature + docstring + path/lines).
- **Recipes** (`docs/<project>/recipes/`): extracted from notebook code cells and upstream tests.
- Optional: **recipe cards** (`docs/<project>/recipe_cards/`): compact, LLM-digested versions of recipes (offline only).

Design record: `dev/decisions/ADR-021.md`.

### 5) Coverage reporting is mandatory

Each corpus refresh writes:

- `server/chat_api/data/docs/_coverage.json`

and prints a small coverage summary (selected vs skipped-by-size). A separate auditor
(`dev/audit_rag_corpus.py`) can re-scan sources to detect drift and missing files.

### 6) Segmentation and scaling defaults

To reduce cross-tool mixing:

- build a global index and also per-project indices (`--build-project-indices`),
- prefer per-project retrieval when a project hint is present.

For retrieval quality:

- hybrid rerank (embedding similarity + lightweight lexical boost) is supported.

Runtime correctness guardrails:

- API symbol verification and symbol re-read are handled by the chat API backend and
  are tracked separately in `dev/decisions/ADR-020.md`.

## Options considered

1. **Compile Sphinx HTML and index the rendered output**
   - Rejected as a default requirement due to toolchain dependency coupling and fragility
     (server environment should not need to import/install upstream tools).

2. **Import upstream Python packages and scrape docstrings at runtime**
   - Rejected because importing MolSysSuite toolchains into the server inference environment
     risks CUDA/dependency conflicts. Also brittle across versions.

3. **Index only docs (no API/docstrings)**
   - Rejected because it increases the risk of invented APIs and weakens the future agent
     capability to choose precise functions.

4. **Hard-cap corpus sizes aggressively**
   - Rejected initially. We prefer “include + measure” (coverage report) and only introduce
     more restrictive defaults once real size/latency bottlenecks appear.

## Consequences

- Corpus refresh becomes a reproducible, offline-friendly batch job suitable for the
  offline GPU node.
- The server can remain “docs + RAG + inference” focused without importing upstream tools.
- We can cite published documentation reliably via anchors.
- API correctness can improve because docstrings/examples are retrievable.
- If the corpus grows substantially, we will rely on the scaling plan below.

## Scaling plan (if corpus grows too large)

If snapshot size, index size, or retrieval latency becomes problematic:

1. **Derived corpus compaction**
   - Generate curated “concept cards” / summaries / FAQ pages from the literal snapshot.
   - Keep provenance metadata (inputs, commit SHAs, generation prompt/model).
   - Keep literal snapshot; derived corpus is additive.

2. **Vector store upgrade**
   - Replace the pickled in-memory index with a persistent ANN store (e.g. FAISS),
     as already anticipated by ADR-004.

3. **More segmentation and filtering**
   - Maintain per-project (and potentially per-subsystem) indices.
   - Add metadata filters (project, doc/api_surface, path patterns) before retrieval.

4. **Two-stage retrieval**
   - Preselect by ANN, rerank with stronger lexical/BM25 or learned reranker.

5. **Operational strategies**
   - Build/refresh indices on the offline node and deploy artifacts to the serving host.
   - Cache query embeddings and frequent retrieval results.
